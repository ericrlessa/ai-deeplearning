{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHAenzcx-t9U"
   },
   "source": [
    "<span style=\" color: yellow; font-size: 24px;\">Deep Learning 1 Project _ Group 5:<br>Tweet Sentiment Extraction (Kaggle Â· Featured Code Competition)<br></span><span style=\"font-size: 22px;\">\n",
    "Shrey\tPatel\t101541370<br>\n",
    "Sam\tEmami\t101575471<br>\n",
    "Eric\tLessa\t101549935<br>\n",
    "Dwip\tMakwana\t101483523<br>\n",
    "Moossa\tHussain\t101542820<br>\n",
    "Chaoyu\tLiu\t101573622<br>\n",
    "Devanshi \tDave\t101582208<br>\n",
    "Rutika\tBhuva\t101551781<br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8woVWkoG-t9W"
   },
   "source": [
    "<span style=\" color: yellow; font-size: 24px;\">Use This Template **by memeber name**: </span>description for each part<span style=\"font-size: 22px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:27.365036Z",
     "iopub.status.busy": "2025-02-02T00:42:27.364733Z",
     "iopub.status.idle": "2025-02-02T00:42:46.678027Z",
     "shell.execute_reply": "2025-02-02T00:42:46.677067Z",
     "shell.execute_reply.started": "2025-02-02T00:42:27.365015Z"
    },
    "id": "SCAGkvve-t9W",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->shap) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->shap) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->shap) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->shap) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->shap) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->shap) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->shap) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->shap) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->shap) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->shap) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->shap) (2024.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: pipeline in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Name: torchvision\n",
      "Version: 0.20.1+cu121\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: numpy, pillow, torch\n",
      "Required-by: easyocr, fastai, timm\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "!pip install transformers\n",
    "!pip install pipeline\n",
    "!pip install datasets\n",
    "!pip show torchvision\n",
    "!pip install evaluate\n",
    "\n",
    "#go to https://graphviz.gitlab.io/download/ and install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXZGn0sW-t9Y"
   },
   "source": [
    "<span style=\"color: yellow; font-size: 24px;\">Hugging Face Transformers Tools for Using Pre-trained LLMs:<br><br></span>\n",
    "<span style=\"color: yellow; font-size: 24px;\">pipeline: </span><span style=\"font-size: 22px;\"> It is like a convenient wrapper or helper that simplifies the process of working with models such as those loaded with AutoModelForSequenceClassification and their associated tokenizers.<br>It integrates with pre-trained models and tokenizers for specific tasks and perform NLP tasks and the processes such as:<br>\n",
    "Loading the model.<br>\n",
    "Tokenizing the input text.<br>\n",
    "Generating predictions.<br>\n",
    "Post-processing the output (if necessary)<br><br></span>\n",
    "<span style=\"color: yellow; font-size: 24px;\">AutoModelForSequenceClassification: </span><span style=\"font-size: 22px;\"> Loading Pre-trained Models designed for sequence classification tasks. Sequence Classification refers to tasks where you classify an entire sequence of text (like a sentence or document) into a category. Examples include:<br>\n",
    "<span style=\"color: red\">Sentiment analysis (positive, negative, neutral)</span><br>\n",
    "Topic classification (news, sports, politics)<br>\n",
    "Spam detection<br>\n",
    "Intent classification (e.g., order, question, complaint)<br>\n",
    "\"Auto\" in the Name: The Auto prefix in the class name signifies its flexibility. You can use it to load various pre-trained models from different architectures (BERT, RoBERTa, DistilBERT, etc.) simply by specifying the model name or path.<br><br></span>\n",
    "<span style=\"color: yellow; font-size: 24px;\">AutoTokenizer: </span><span style=\"font-size: 22px;\"> tokenizing the inputs. The tokenizer ensures that:<br>\n",
    "The tokenized input matches the vocabulary and format expected by the model.<br>\n",
    "The inputs include features like input_ids, attention_mask, and token_type_ids (if applicable).<br><br></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:46.680119Z",
     "iopub.status.busy": "2025-02-02T00:42:46.679784Z",
     "iopub.status.idle": "2025-02-02T00:42:46.684983Z",
     "shell.execute_reply": "2025-02-02T00:42:46.684157Z",
     "shell.execute_reply.started": "2025-02-02T00:42:46.680084Z"
    },
    "id": "y-CwZu9W-t9Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shap\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import EvalPrediction\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    DefaultDataCollator,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:46.686783Z",
     "iopub.status.busy": "2025-02-02T00:42:46.686588Z",
     "iopub.status.idle": "2025-02-02T00:42:46.705112Z",
     "shell.execute_reply": "2025-02-02T00:42:46.704271Z",
     "shell.execute_reply.started": "2025-02-02T00:42:46.686765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Disable wandb\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:46.706858Z",
     "iopub.status.busy": "2025-02-02T00:42:46.706600Z",
     "iopub.status.idle": "2025-02-02T00:42:46.732273Z",
     "shell.execute_reply": "2025-02-02T00:42:46.731498Z",
     "shell.execute_reply.started": "2025-02-02T00:42:46.706839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SentimentExtraction:\n",
    "    \n",
    "    def __init__(self, train_path):\n",
    "        self.train_df = pd.read_csv(train_path)\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.squad_metric = evaluate.load(\"squad\")\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Clean and prepare the data\"\"\"\n",
    "        \n",
    "        self.train_df = self.train_df.dropna(subset=['text'])\n",
    "        \n",
    "        dataset = Dataset.from_pandas(self.train_df)\n",
    "        split_data = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "        train_dataset = split_data['train']\n",
    "        self.test_dataset = split_data['test']\n",
    "\n",
    "        train_val_dataset = train_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "        train_dataset = train_val_dataset['train']\n",
    "        val_dataset = train_val_dataset['test']\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "    def setup_model(self, model_name):\n",
    "        \"\"\"Initialize the model and tokenizer\"\"\"\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # Initialize for binary classification (2 labels)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "        \n",
    "        # Move model to available device\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(device)\n",
    "\n",
    "    def tokenize_question_context(self, examples):\n",
    "        sentiment = examples['sentiment']\n",
    "        tweet = examples['text']\n",
    "        span = examples['selected_text']\n",
    "\n",
    "        tokenized_qa = self.tokenizer(sentiment, # question\n",
    "                                tweet, # context\n",
    "                                padding='max_length',\n",
    "                                return_offsets_mapping=True)\n",
    "\n",
    "        tokenized_qa[\"start_positions\"] = []\n",
    "        tokenized_qa[\"end_positions\"] = []\n",
    "\n",
    "        start_char = tweet.find(span)\n",
    "        end_char = start_char + len(span)\n",
    "\n",
    "        offsets = tokenized_qa.pop(\"offset_mapping\")\n",
    "        start_token = end_token = None\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "                break\n",
    "\n",
    "        tokenized_qa[\"start_positions\"].append(start_token)\n",
    "        tokenized_qa[\"end_positions\"].append(end_token)\n",
    "\n",
    "        if start is None or end is None:\n",
    "            raise ValueError(\"Data set error: Could not identify start/end for span/context.\")\n",
    "\n",
    "        return tokenized_qa\n",
    "\n",
    "    def compute_metrics(self, eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        start_preds, end_preds = predictions  # Unpack start and end logits\n",
    "        start_labels, end_labels = labels     # Unpack start and end positions\n",
    "\n",
    "        # Convert logits to predicted indices\n",
    "        start_preds = np.argmax(start_preds, axis=1)  # Shape: (100,)\n",
    "        end_preds = np.argmax(end_preds, axis=1)      # Shape: (100,)\n",
    "\n",
    "        total_jaccard = 0\n",
    "        num_samples = len(start_preds)\n",
    "\n",
    "        # Create prediction and reference text spans\n",
    "        preds = []\n",
    "        refs = []\n",
    "        for i in range(len(start_preds)):\n",
    "            # Decode predicted text span\n",
    "            pred_tokens = self.tokenizer.decode(range(start_preds[i], end_preds[i] + 1))            \n",
    "            preds.append({\"id\": str(i), \"prediction_text\": pred_tokens})\n",
    "            \n",
    "            # Decode reference text span\n",
    "            ref_tokens = self.tokenizer.decode(range(start_labels[i, 0], end_labels[i, 0] + 1))\n",
    "            refs.append({\"id\": str(i), \"answers\": {\"text\": [ref_tokens], \"answer_start\": [start_labels[i, 0]]}})\n",
    "\n",
    "            jaccard = SentimentExtraction.jaccard_tokens(pred_tokens, ref_tokens)\n",
    "            total_jaccard += jaccard\n",
    "\n",
    "        avg_jaccard = total_jaccard / num_samples\n",
    "\n",
    "        # Compute SQuAD metrics\n",
    "        squad_result = self.squad_metric.compute(predictions=preds, references=refs)\n",
    "\n",
    "        return {\n",
    "            \"exact_match\": f\"{squad_result['exact_match']:.2f}%\",\n",
    "            \"f1_score\": f\"{squad_result['f1']:.2f}%\",\n",
    "            \"avg_jaccard\": f\"{avg_jaccard:.2f}\"\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard_tokens(pred_tokens, ref_tokens):\n",
    "        pred_set = set(pred_tokens.lower().split())\n",
    "        ref_set = set(ref_tokens.lower().split())\n",
    "        intersection = pred_set.intersection(ref_set)\n",
    "        union = pred_set.union(ref_set)\n",
    "        jaccard = len(intersection) / len(union) if union else 0\n",
    "        return jaccard\n",
    "\n",
    "    def train(self, model_name, learning_rate, epochs, checkpoint=None):\n",
    "        # Prepare data\n",
    "        print(\"\\nPreparing datasets...\")\n",
    "        print(\"Dataset columns:\", self.train_df.columns.tolist())\n",
    "        train_dataset, eval_dataset = self.prepare_data()\n",
    "        print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "        print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
    "\n",
    "        # Setup model\n",
    "        print(\"\\nSetting up model...\")\n",
    "        self.setup_model(model_name)\n",
    "\n",
    "        tokenized_train = train_dataset.map(self.tokenize_question_context)\n",
    "\n",
    "        tokenized_eval = eval_dataset.map(self.tokenize_question_context)\n",
    "\n",
    "        print(f\"\\nSelecting {tokenized_train} training samples and {tokenized_eval} evaluation samples...\")\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            f\"finetune-BERT-tweet\",\n",
    "            evaluation_strategy = \"epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=0.01,\n",
    "            save_total_limit=2,\n",
    "            fp16=True\n",
    "        )\n",
    "\n",
    "        #early_stopping = EarlyStoppingCallback(early_stopping_patience=3)  # Stop if no improvement after 3 evaluations\n",
    "\n",
    "        #small_train_dataset = tokenized_train.shuffle(seed=42).select(range(500))\n",
    "        #small_eval_dataset = tokenized_eval.shuffle(seed=42).select(range(100))\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_eval,\n",
    "            #train_dataset=small_train_dataset,\n",
    "            #eval_dataset=small_eval_dataset,\n",
    "            data_collator=DataCollatorWithPadding(self.tokenizer),\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=self.compute_metrics\n",
    "         #    callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        print(\"\\nStarting training...\")\n",
    "        try:\n",
    "            trainer.train(resume_from_checkpoint=checkpoint)\n",
    "            print(\"\\nTraining completed successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError during training: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "        # # Save the model\n",
    "        # print(\"\\nSaving model...\")\n",
    "        # trainer.save_model(\"sentiment_extraction_tweet_model\")\n",
    "\n",
    "    # added v2\n",
    "    def train_multiple_models(self, model_configs):\n",
    "        \"\"\"Train multiple models with specific configurations and compare results\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for config in model_configs:\n",
    "            model_name = config[\"model_name\"]\n",
    "            learning_rate = config[\"learning_rate\"]\n",
    "            epochs = config[\"epochs\"]\n",
    "            \n",
    "            print(f\"\\nTraining model: {model_name}\")\n",
    "            self.train(model_name, learning_rate, epochs)\n",
    "            metrics = self.evaluate_test_dataset()\n",
    "            metrics[\"model\"] = model_name\n",
    "            results.append(metrics)\n",
    "            \n",
    "            # Save model\n",
    "            self.model.save_pretrained(f\"sentiment_extraction_{model_name.replace('/', '_')}\")\n",
    "\n",
    "        # Print performance comparison\n",
    "        print(\"\\nModel Performance Comparison:\")\n",
    "        for res in results:\n",
    "            print(f\"\\nModel: {res['model']}\")\n",
    "            print(f\"Exact Match: {res['exact_match']}\")\n",
    "            print(f\"F1 Score: {res['f1_score']}\")\n",
    "            print(f\"Avg Jaccard: {res['avg_jaccard']}\")\n",
    "    \n",
    "    def baseline(self):\n",
    "        dataset, _ = self.prepare_data()\n",
    "        self.compute_metrics_for_dataset(dataset)\n",
    "\n",
    "    # def evaluate_test_dataset(self):\n",
    "    #     print('\\nEvaluating the test dataset at the end of training...')\n",
    "    #     self.compute_metrics_for_dataset(self.test_dataset)\n",
    "\n",
    "    # added v2\n",
    "    def evaluate_test_dataset(self):\n",
    "        print('\\nEvaluating the test dataset at the end of training...')\n",
    "        if not self.test_dataset:\n",
    "            print(\"Test dataset is empty or not available.\")\n",
    "            return {\"exact_match\": 0.0, \"f1_score\": 0.0, \"avg_jaccard\": 0.0}\n",
    "        \n",
    "        total_jaccard = 0\n",
    "        preds = []\n",
    "        refs = []\n",
    "        for i in range(len(self.test_dataset)):\n",
    "            sample = self.test_dataset[i]\n",
    "            sentiment = sample['sentiment']\n",
    "            tweet = sample['text']\n",
    "            span = sample['selected_text']\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                pred_text = self.predict_span(sentiment, tweet)\n",
    "\n",
    "                preds.append({\"id\": str(i), \"prediction_text\": pred_text})\n",
    "                refs.append({\"id\": str(i), \"answers\": {\"text\": [span], \"answer_start\": [tweet.find(span)]}})\n",
    "\n",
    "                total_jaccard += SentimentExtraction.jaccard_text(pred_text, span)\n",
    "        \n",
    "        squad_result = self.squad_metric.compute(predictions=preds, references=refs)\n",
    "        return {\n",
    "            \"exact_match\": float(squad_result['exact_match']),\n",
    "            \"f1_score\": float(squad_result['f1']),\n",
    "            \"avg_jaccard\": float(total_jaccard/len(self.test_dataset))\n",
    "        }\n",
    "\n",
    "    def compute_metrics_for_dataset(self, dataset):\n",
    "        total_jaccard = 0\n",
    "        preds = []\n",
    "        refs = []\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            sentiment = sample['sentiment']\n",
    "            tweet = sample['text']\n",
    "            span = sample['selected_text']\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                pred_text = self.predict_span(sentiment, tweet)\n",
    "\n",
    "                preds.append({\"id\": str(i), \"prediction_text\": pred_text})\n",
    "                refs.append({\"id\": str(i), \"answers\": {\"text\": [span], \"answer_start\": [tweet.find(span)]}})\n",
    "\n",
    "                total_jaccard += SentimentExtraction.jaccard_text(pred_text, span)\n",
    "        \n",
    "        squad_result = self.squad_metric.compute(predictions=preds, references=refs)\n",
    "        print(\"Prediction results:\")\n",
    "        print(f\"\\texact_match: {squad_result['exact_match']:.2f}%\")\n",
    "        print(f\"\\tf1_score: {squad_result['f1']:.2f}%\")\n",
    "        print(f\"\\tavg_jaccard: {total_jaccard/len(dataset):.2f}\")\n",
    "\n",
    "    def predict_span(self, sentiment,tweet):\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "                sentiment,  # the sentiment question\n",
    "                tweet,      # the tweet context\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "        \n",
    "        start_position = torch.argmax(start_logits, dim=-1)\n",
    "        end_position = torch.argmax(end_logits, dim=-1)\n",
    "        \n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "                \n",
    "        pred_span_tokens = tokens[start_position:end_position+1]\n",
    "        pred_text = self.tokenizer.convert_tokens_to_string(pred_span_tokens)\n",
    "        return pred_text\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard_text(text, span):\n",
    "        set1 = set(text.lower().split())\n",
    "        set2 = set(span.lower().split())\n",
    "        jaccard = len(set1 & set2) / len(set1 | set2)  # Intersection / Union\n",
    "        return jaccard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:46.733190Z",
     "iopub.status.busy": "2025-02-02T00:42:46.732950Z",
     "iopub.status.idle": "2025-02-02T00:42:46.749068Z",
     "shell.execute_reply": "2025-02-02T00:42:46.748255Z",
     "shell.execute_reply.started": "2025-02-02T00:42:46.733170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def zip_and_download_models(self):\n",
    "        \"\"\"Zip all trained models and provide a link to download them\"\"\"\n",
    "        zip_filename = \"trained_models.zip\"\n",
    "        shutil.make_archive(\"trained_models\", 'zip', \".\")\n",
    "        print(f\"Models zipped successfully: {zip_filename}\")\n",
    "        \n",
    "        from IPython.display import FileLink\n",
    "        return FileLink(zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:46.749942Z",
     "iopub.status.busy": "2025-02-02T00:42:46.749753Z",
     "iopub.status.idle": "2025-02-02T00:42:46.765550Z",
     "shell.execute_reply": "2025-02-02T00:42:46.764748Z",
     "shell.execute_reply.started": "2025-02-02T00:42:46.749926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize processor\n",
    "    print(\"Initializing data processor...\")\n",
    "    processor = SentimentExtraction('/kaggle/input/tweet-extraction/train.csv')\n",
    "    \n",
    "    #model_name = \"bert-base-uncased\"\n",
    "    # model_name = \"distilbert-base-uncased\"\n",
    "    # processor.train(model_name)\n",
    "    \n",
    "    # processor.evaluate_test_dataset()\n",
    "\n",
    "    model_configs = [\n",
    "        {\"model_name\": \"distilbert-base-uncased\", \"learning_rate\": 2e-5, \"epochs\": 3},\n",
    "        {\"model_name\": \"bert-base-uncased\", \"learning_rate\": 3e-5, \"epochs\": 5},\n",
    "        {\"model_name\": \"roberta-base\", \"learning_rate\": 1e-5, \"epochs\": 4}\n",
    "    ]\n",
    "    \n",
    "    processor.train_multiple_models(model_configs)\n",
    "\n",
    "    return processor\n",
    "\n",
    "def print_baseline():\n",
    "    # Initialize processor\n",
    "    print(\"Initializing data processor...\")\n",
    "    processor = SentimentExtraction('/kaggle/input/tweet-extraction/train.csv')\n",
    "\n",
    "    #model_name = \"bert-base-uncased\"\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    processor.setup_model(model_name)\n",
    "    processor.baseline()\n",
    "\n",
    "def prediction_test(processor):\n",
    "    tweet = \" you guys didn`t say hi or answer my questions yesterday  but nice songs.\"\n",
    "    sentiment = \"positive\"\n",
    "\n",
    "    sentiment_text = processor.predict_span(sentiment, tweet)\n",
    "\n",
    "    print(f\"Predicted sentiment span: {sentiment_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T00:42:46.766709Z",
     "iopub.status.busy": "2025-02-02T00:42:46.766434Z",
     "iopub.status.idle": "2025-02-02T00:44:27.565215Z",
     "shell.execute_reply": "2025-02-02T00:44:27.564490Z",
     "shell.execute_reply.started": "2025-02-02T00:42:46.766682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data processor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results:\n",
      "\texact_match: 0.38%\n",
      "\tf1_score: 9.44%\n",
      "\tavg_jaccard: 0.07\n"
     ]
    }
   ],
   "source": [
    "print_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T00:44:27.567220Z",
     "iopub.status.busy": "2025-02-02T00:44:27.566996Z",
     "iopub.status.idle": "2025-02-02T04:14:55.574770Z",
     "shell.execute_reply": "2025-02-02T04:14:55.573271Z",
     "shell.execute_reply.started": "2025-02-02T00:44:27.567201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data processor...\n",
      "\n",
      "Training model: distilbert-base-uncased\n",
      "\n",
      "Preparing datasets...\n",
      "Dataset columns: ['textID', 'text', 'selected_text', 'sentiment']\n",
      "Train dataset size: 22258\n",
      "Eval dataset size: 2474\n",
      "\n",
      "Setting up model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c481cfb42ab4d8395dd87f9b4346da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22258 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d528e4dc2cb498790cd632e3a9a1574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2474 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting Dataset({\n",
      "    features: ['textID', 'text', 'selected_text', 'sentiment', '__index_level_0__', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 22258\n",
      "}) training samples and Dataset({\n",
      "    features: ['textID', 'text', 'selected_text', 'sentiment', '__index_level_0__', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 2474\n",
      "}) evaluation samples...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`evaluation_strategy` is deprecated and will be removed in version 4.46 of ð¤ Transformers. Use `eval_strategy` instead\n",
      "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4176' max='4176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4176/4176 30:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.036000</td>\n",
       "      <td>0.959598</td>\n",
       "      <td>51.17%</td>\n",
       "      <td>71.56%</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.929966</td>\n",
       "      <td>54.49%</td>\n",
       "      <td>73.54%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>0.950274</td>\n",
       "      <td>54.12%</td>\n",
       "      <td>73.74%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed successfully!\n",
      "\n",
      "Evaluating the test dataset at the end of training...\n",
      "\n",
      "Training model: bert-base-uncased\n",
      "\n",
      "Preparing datasets...\n",
      "Dataset columns: ['textID', 'text', 'selected_text', 'sentiment']\n",
      "Train dataset size: 22258\n",
      "Eval dataset size: 2474\n",
      "\n",
      "Setting up model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391e37e8e4204803876a2a0b02a94d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408a54204a224c55b3a7a9040cbfcb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65fd76c001d4a269fef2e8ac303f107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f6b2ac2de64b16b2dad2bafa22670f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3201890715ce420bbf8f05738d133a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Parameter 'function'=<bound method SentimentExtraction.tokenize_question_context of <__main__.SentimentExtraction object at 0x7a9c9dcdcf40>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec344066d09345128103c59748f91434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22258 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee706767d1d47dbb44fbe825d27dbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2474 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting Dataset({\n",
      "    features: ['textID', 'text', 'selected_text', 'sentiment', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 22258\n",
      "}) training samples and Dataset({\n",
      "    features: ['textID', 'text', 'selected_text', 'sentiment', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 2474\n",
      "}) evaluation samples...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`evaluation_strategy` is deprecated and will be removed in version 4.46 of ð¤ Transformers. Use `eval_strategy` instead\n",
      "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6960' max='6960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6960/6960 1:38:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.005800</td>\n",
       "      <td>0.966937</td>\n",
       "      <td>51.86%</td>\n",
       "      <td>72.61%</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.949681</td>\n",
       "      <td>55.78%</td>\n",
       "      <td>73.76%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>1.046725</td>\n",
       "      <td>53.52%</td>\n",
       "      <td>73.85%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.464300</td>\n",
       "      <td>1.209296</td>\n",
       "      <td>53.64%</td>\n",
       "      <td>74.09%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>1.357435</td>\n",
       "      <td>53.60%</td>\n",
       "      <td>74.05%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed successfully!\n",
      "\n",
      "Evaluating the test dataset at the end of training...\n",
      "\n",
      "Training model: roberta-base\n",
      "\n",
      "Preparing datasets...\n",
      "Dataset columns: ['textID', 'text', 'selected_text', 'sentiment']\n",
      "Train dataset size: 22258\n",
      "Eval dataset size: 2474\n",
      "\n",
      "Setting up model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78cf47ced644930b649db923f3943d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b7728bf6f54645bf2ec6fa22b69a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44773306c9148d9a59928e34461c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb43fed44d294c86a9f18606ee50a356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403c5fd98b3848f3821f712d4cde95c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861a8947b57345ed9863315abc5c10cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa5e1df3ed0479a9afab4c83f4d0d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22258 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b07200e03b4496fa07a03e599d3eb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2474 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting Dataset({\n",
      "    features: ['textID', 'text', 'selected_text', 'sentiment', '__index_level_0__', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 22258\n",
      "}) training samples and Dataset({\n",
      "    features: ['textID', 'text', 'selected_text', 'sentiment', '__index_level_0__', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 2474\n",
      "}) evaluation samples...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`evaluation_strategy` is deprecated and will be removed in version 4.46 of ð¤ Transformers. Use `eval_strategy` instead\n",
      "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5568' max='5568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5568/5568 1:19:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Avg Jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.075300</td>\n",
       "      <td>0.929769</td>\n",
       "      <td>56.83%</td>\n",
       "      <td>66.15%</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.869400</td>\n",
       "      <td>0.866869</td>\n",
       "      <td>60.71%</td>\n",
       "      <td>68.58%</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>0.872281</td>\n",
       "      <td>59.66%</td>\n",
       "      <td>68.54%</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.759600</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>60.79%</td>\n",
       "      <td>69.52%</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed successfully!\n",
      "\n",
      "Evaluating the test dataset at the end of training...\n",
      "\n",
      "Model Performance Comparison:\n",
      "\n",
      "Model: distilbert-base-uncased\n",
      "Exact Match: 37.88209606986899\n",
      "F1 Score: 67.83350935989824\n",
      "Avg Jaccard: 0.5685776288731035\n",
      "\n",
      "Model: bert-base-uncased\n",
      "Exact Match: 36.098981077147016\n",
      "F1 Score: 67.37174150679255\n",
      "Avg Jaccard: 0.562081638751201\n",
      "\n",
      "Model: roberta-base\n",
      "Exact Match: 52.001455604075694\n",
      "F1 Score: 70.20428295577787\n",
      "Avg Jaccard: 0.6431049458925355\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SentimentExtraction' object has no attribute 'zip_and_download_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fc71e5087292>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-b9835f0b77ef>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_multiple_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdownload_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_and_download_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Download your trained models here:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SentimentExtraction' object has no attribute 'zip_and_download_models'"
     ]
    }
   ],
   "source": [
    "processor = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-02T04:14:55.575503Z",
     "iopub.status.idle": "2025-02-02T04:14:55.575793Z",
     "shell.execute_reply": "2025-02-02T04:14:55.575686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prediction_test(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T04:21:54.939516Z",
     "iopub.status.busy": "2025-02-02T04:21:54.939176Z",
     "iopub.status.idle": "2025-02-02T04:25:00.156987Z",
     "shell.execute_reply": "2025-02-02T04:25:00.156264Z",
     "shell.execute_reply.started": "2025-02-02T04:21:54.939489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models zipped successfully: trained_models.zip\n",
      "Download your trained models here: /kaggle/working/trained_models.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Reload SentimentExtraction class and attach trained models\n",
    "processor = SentimentExtraction('/kaggle/input/tweet-extraction/train.csv')\n",
    "\n",
    "# Dynamically add zip_and_download_models method\n",
    "def zip_and_download_models(self):\n",
    "    \"\"\"Zip all trained models and provide a link to download them\"\"\"\n",
    "    zip_filename = \"trained_models.zip\"\n",
    "    shutil.make_archive(\"trained_models\", 'zip', \".\")\n",
    "    print(f\"Models zipped successfully: {zip_filename}\")\n",
    "    return FileLink(zip_filename)\n",
    "\n",
    "# Attach the method dynamically to SentimentExtraction class\n",
    "SentimentExtraction.zip_and_download_models = zip_and_download_models\n",
    "\n",
    "\n",
    "download_link = processor.zip_and_download_models()\n",
    "print(\"Download your trained models here:\", download_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-02T04:14:55.576573Z",
     "iopub.status.idle": "2025-02-02T04:14:55.576907Z",
     "shell.execute_reply": "2025-02-02T04:14:55.576756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def trainFromCheckpoint(checkpoint):\n",
    "    # Initialize processor\n",
    "    print(\"Initializing data processor...\")\n",
    "    processor = SentimentExtraction('/kaggle/input/tweet-extraction/train.csv')\n",
    "\n",
    "    processor.train(checkpoint)\n",
    "\n",
    "\n",
    "#trainFromCheckpoint('/kaggle/working/finetune-BERT-tweet/checkpoint-8000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKgnOStR-t9a"
   },
   "source": [
    "<span style=\"font-size: 22px;\">From the Hugging Face Transformers library, acquires a pre-trained BERT-based sentiment analysis model (**LLM**), with its appropriate pipeline (**classifier**) and **tokenizer**.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions sentiment extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubw4qATO-t9a"
   },
   "source": [
    "<span style=\" color: yellow; font-size: 24px;\">Importan Note by Sam: </span><span style=\"font-size: 22px;\">LLMs such as BERT, LLama, GPTT,etc., and BERT-based models (like distilbert-base-uncased-finetuned-sst-2-english) do not include an activation function (e.g., softmax or sigmoid) at their output layer by default. Instead, they output logits, which are raw, unnormalized scores for each class. The activation function, if needed, is applied externally depending on the specific task and requirements.<br> BERT is a general-purpose transformer model. By omitting the activation function, it can be fine-tuned for various tasks: Multi-class classification (e.g., softmax), Binary classification (e.g., sigmoid), Regression tasks (no activation function).<br></span>\n",
    "\n",
    "\n",
    "<span style=\" color: yellow; font-size: 24px;\">outputs</span> <span style=\"font-size: 22px;\">It is an object of type ModelOutput, specifically tailored for the model we are using. Here we didn't simply print the result of the sentiment for the each tweet, but we used output.logits to go access the detailed classification results for each text for further word by word analysis in SHAP.<br></span>\n",
    "<span style=\" color: yellow; font-size: 24px;\">logits:</span> <span style=\"font-size: 22px;\"> is the modelâs raw output before applying the activation function. logits are unnormalized scores, which can be positive, negative, or zero, depending on the modelâs confidence in each class. Here \"outputs.logits\" is a tensor containing the raw, unnormalized predictions for each input sequence. Each row in the tensor corresponds to one input in texts, and each column corresponds to a class.<br></span>\n",
    "<span style=\" color: yellow; font-size: 24px;\">Normalize logits to probabilities:</span><span style=\"font-size: 22px;\"> by applying softmax we normalize the raw predictions for each tweet to probabilities (the results are printed for clarity).<br></span>\n",
    "<span style=\" color: yellow; font-size: 24px;\">detach()</span><span style=\"font-size: 22px;\"> We use it since we donât want to compute gradients for the tensor. Since probabilities are used only for prediction (not training), thereâs no need to track gradients, so detach() avoids unnecessary computational overhead.<br></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-02T04:14:55.578021Z",
     "iopub.status.idle": "2025-02-02T04:14:55.578289Z",
     "shell.execute_reply": "2025-02-02T04:14:55.578186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "# Load pre-trained sentiment analysis model and tokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "\n",
    "# Tokenizer and model for SHAP\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-02T04:14:55.579570Z",
     "iopub.status.idle": "2025-02-02T04:14:55.579885Z",
     "shell.execute_reply": "2025-02-02T04:14:55.579774Z"
    },
    "id": "13vHVSQW-t9a",
    "outputId": "01282d8b-eeee-420c-926b-1302f1db0109",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define a wrapper for the classifier to work with SHAP\n",
    "def classifier_wrapper(texts):\n",
    "    tokens = tokenizer(list(texts), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    outputs = model(**tokens)\n",
    "    probabilities = outputs.logits.softmax(dim=1).detach().numpy()\n",
    "    print(f\"\\nlogits contains tweets' unnormalized prediction scores for each class(positive / negative):\\n{outputs.logits}\\n\")\n",
    "    return probabilities\n",
    "\n",
    "# Select a subset of the training data for SHAP analysis\n",
    "sample_texts = train_df[\"text\"].sample(10, random_state=42).tolist()\n",
    "print(\"Sample Texts:\")\n",
    "print(sample_texts)\n",
    "print(f\"Probibilities after normalizing logits by softwax:\\n {classifier_wrapper(sample_texts)}\")  # Should output a numpy array of probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hF9hc2bz-t9a"
   },
   "source": [
    "<span style=\" color: yellow; font-size: 24px;\">SHAP Analysis:</span><span style=\"font-size: 22px;\"> SHAP is based on <u>Shapley values</u> which is a concept from <u>Game Theory</u>. Imagine a group of players collaborating to achieve a common goal. Shapley values determine how to fairly distribute the rewards or profits among the players based on their individual contributions.\n",
    "In the context of machine learning, features of a data point can be seen as \"players\" contributing to the model's prediction.<br> SHAP aims to fairly attribute the \"credit\" (or \"blame\") for the model's output to each feature.<br>\n",
    "For complex models, SHAP often uses <u>approximations</u> or <u>sampling techniques</u> to estimate Shapley values.<br>\n",
    "The explainer considers <u>all possible combinations of features (words or tokens)</u> in the sample.\n",
    "For each combination, it calculates the model's prediction.<br>\n",
    "This process helps determine how much each feature contributes to the overall prediction.\n",
    "Shapley Values are assigned based on the calculated predictions for different feature combinations,\n",
    "SHAP assigns a value to each feature.\n",
    "</br></br></spn>\n",
    "</span>\n",
    "<span style=\" color: yellow; font-size: 24px;\">shap.Explainer:</span><span style=\"font-size: 22px;\"> Is the core class in the SHAP library. It encapsulates the model and the method for <u>calculating</u> SHAP values, which quantify the <u>contribution of each feature</u> (in this case, words or tokens) <u>to the model's prediction</u> for a given sample.<br>\n",
    "The Explainer needs \"classifier_wrapper\" function to understand how the model makes predictions.<br><br></span>\n",
    "\n",
    "<span style=\" color: yellow; font-size: 24px;\">Note: </span><span style=\"font-size: 22px;\">\n",
    "When classifier_wrapper is run by SHAP, there are six or less probibilities for the ten tweets in sample_texts. It is because the tokenizer applies padding and truncation to the input. If multiple texts are identical, the tokenizer may return the same tokens for duplicates. If sample_texts contains duplicate or very similar tweets, their logits will be identical, and we might get fewer output tensors.<br><br></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "2bdfb5713df34018959bf3f4e89e548b",
      "9d94eb89faaa421dadcaf0e2181df74d",
      "305de2c39a00463b9552380aec2c78ef",
      "a104b74d08d540398965e35fd021b540",
      "13f142a64ce54aa1ba4be86e83fed3f2",
      "6864e9a6e7774f848f563b8fdda6f4e5",
      "ed52ddcdc74049e99fb2cdaa1fbf9961"
     ]
    },
    "execution": {
     "iopub.status.busy": "2025-02-02T04:14:55.580667Z",
     "iopub.status.idle": "2025-02-02T04:14:55.580970Z",
     "shell.execute_reply": "2025-02-02T04:14:55.580830Z"
    },
    "id": "UZ0Zfs2--t9a",
    "outputId": "618aaa65-2e38-4285-9ed4-da05a7e0112b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Explain predictions using SHAP\n",
    "# This line integrates the model in the function to SHAP and encapsulates\n",
    "# the necessary information to compute SHAP values for the given model and data.\n",
    "explainer = shap.Explainer(classifier_wrapper, tokenizer)\n",
    "shap_values = explainer(sample_texts)\n",
    "\n",
    "# Visualize the SHAP values for each word:\n",
    "# Output 0 and Output 1: predicted probabilities for two classes\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"\\nSHAP Analysis for Text {i + 1}: {text}\")\n",
    "    shap.plots.text(shap_values[i])\n",
    "'''\n",
    "#The following code save SHAP analysis results into different html files for each tweet:\n",
    "\n",
    "#shap.save_html(\"shap_analysis.html\", shap_values)\n",
    "# Manually set the base value if explainer.expected_value is None\n",
    "# For classification tasks, the base value can be the mean of logits\n",
    "if explainer.expected_value is None:\n",
    "    print(\"explainer.expected_value is None. Computing a manual base value.\")\n",
    "    base_value = np.mean([np.mean(values.values) for values in shap_values])\n",
    "else:\n",
    "    base_value = explainer.expected_value\n",
    "\n",
    "# Loop through all SHAP values and save each as a separate force plot\n",
    "for i, shap_value in enumerate(shap_values):\n",
    "    # Debugging: Print base value and SHAP values\n",
    "    print(f\"Processing Text {i + 1}\")\n",
    "    print(f\"Base Value: {base_value}\")\n",
    "    print(f\"SHAP Values for Text {i + 1}: {shap_value.values}\")\n",
    "\n",
    "    # Check if shap_value.values is None\n",
    "    if shap_value.values is None:\n",
    "        print(f\"Skipping Text {i + 1} due to missing values.\")\n",
    "        continue\n",
    "\n",
    "    # Handle multi-output models (if applicable)\n",
    "    if isinstance(base_value, list):\n",
    "        base_value = base_value[0]  # Use the base value for the first output\n",
    "\n",
    "    # Create a force plot for the current sample\n",
    "    try:\n",
    "        vis = shap.plots.force(base_value, shap_value.values)\n",
    "\n",
    "        # Save the visualization as an HTML file\n",
    "        file_name = f\"shap_analysis_{i + 1}.html\"\n",
    "        shap.save_html(file_name, vis)\n",
    "        print(f\"Saved SHAP visualization for Text {i + 1} as {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Text {i + 1}: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-02T04:14:55.581625Z",
     "iopub.status.idle": "2025-02-02T04:14:55.581882Z",
     "shell.execute_reply": "2025-02-02T04:14:55.581780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r checkpoint-9276.zip /kaggle/working/finetune-BERT-tweet/checkpoint-9276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6511228,
     "sourceId": 10519733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6563944,
     "sourceId": 10603868,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
